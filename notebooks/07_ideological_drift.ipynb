{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ideological Drift - Word Drift Using Embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook documents the **Word Drift analysis pipeline** for the BSc thesis:  \n",
    "`Debates, Media, and Discourse: A Computational Analysis of Temporal Shifts in U.S. Presidential Debates and Media Framing Across the Political Spectrum`, written by **Emma Cristina Mora** (emma.mora@studbocconi.it) at **Bocconi University** under the supervision of **Professor Carlo Rasmus Schwarz**.  \n",
    "\n",
    "The objective of this stage is to explore how the **semantic meaning of key political anchors** (e.g., *freedom*, *security*, *immigration*) has evolved in U.S. presidential debates across decades, and how these anchors align with policy themes in both **debates** and **media coverage**. By tracking semantic drift and divergence, the analysis highlights how rhetorical and policy anchors shift, stabilize, or fragment in political discourse.  \n",
    "\n",
    "**Dataset Preparation**  \n",
    "- The input dataset is the **debates_df_themes.csv**, containing ~6,300 utterances enriched with speaker, party, year, decade, and thematic labels.  \n",
    "- Utterances were paired with **SBERT embeddings (all-MiniLM-L6-v2, 384-dim)** previously computed during topic modeling.  \n",
    "- Anchor terms were defined with **alias expansions** to capture linguistic variation (e.g., *security, safety, defense*).  \n",
    "- Filtering removed moderator interventions and retained only **candidate utterances**.  \n",
    "\n",
    "**Anchor Embedding Computation**  \n",
    "- For each anchor, embeddings were grouped by **party × decade** to create centroid representations.  \n",
    "- This enabled measurement of:  \n",
    "  - **Semantic drift**: cosine distance of anchor centroids across consecutive decades.  \n",
    "  - **Party divergence**: cosine distance between Democratic and Republican anchors within the same decade.  \n",
    "\n",
    "**Anchor–Theme Alignment**  \n",
    "- Debate anchor embeddings (2010s–2020s) were compared to **debate theme centroids** to identify their closest policy anchors.  \n",
    "- Media anchors (NYT, WSJ, NYP, 2012–2024) were included via balanced Factiva datasets to compare how **debates vs. media** frame the same anchors.  \n",
    "- Results capture both **policy anchors** (healthcare, immigration, taxes) that map consistently to stable themes, and **rhetorical anchors** (freedom, security, America) that drift between symbolic and policy uses.  \n",
    "\n",
    "**Outputs**  \n",
    "- `semantic_drift.csv` — decade-to-decade semantic distances for each anchor and party.  \n",
    "- `party_divergence.csv` — cross-party divergence within the same decade.  \n",
    "- `anchor_theme_alignment.csv` — mapping of anchors to closest debate and media themes.  \n",
    "\n",
    "**Notebook Contribution**  \n",
    "This pipeline provides a framework for analyzing **ideological drift in political discourse**, enabling:  \n",
    "- Detection of stable vs. drifting anchors in debates.  \n",
    "- Comparison of rhetorical vs. policy anchors.  \n",
    "- Cross-domain framing alignment between **debates** and **media**.  \n",
    "- Empirical evidence on how key political terms are contested, stabilized, or redefined across decades.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Introduction and Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === SETUP ===\n",
    "\n",
    "# standard libraries\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "\n",
    "# for plotting\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# reproducibility (used later for sampling etc.)\n",
    "RANDOM_SEED = 42\n",
    "np.random.seed(RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repository Path: /Users/emmamora/Documents/GitHub/thesis\n",
      "Data Directory: /Users/emmamora/Documents/GitHub/thesis/data\n",
      "Debates Dataset: /Users/emmamora/Documents/GitHub/thesis/data/debates_df_themes.csv\n",
      "Embeddings: /Users/emmamora/Documents/GitHub/thesis/data/topic_modeling/debates_embeddings.npy\n"
     ]
    }
   ],
   "source": [
    "# === FILE PATHS ===\n",
    "\n",
    "# set base repository path (assumes notebook is in repo/notebooks/)\n",
    "REPO_DIR = Path(\".\").resolve().parents[0]\n",
    "\n",
    "# data paths\n",
    "DATA_DIR = REPO_DIR / \"data\"\n",
    "DEBATES_DF_PATH = DATA_DIR / \"debates_df_themes.csv\"\n",
    "EMBEDDINGS_PATH = DATA_DIR / \"topic_modeling\" / \"debates_embeddings.npy\"\n",
    "OUTPUT_PATH = DATA_DIR / \"ideological_drift\" \n",
    "\n",
    "# color palette\n",
    "with open(Path(REPO_DIR / \"color_palette_config.json\")) as f:\n",
    "    palette = json.load(f)\n",
    "\n",
    "print(\"Repository Path:\", REPO_DIR)\n",
    "print(\"Data Directory:\", DATA_DIR)\n",
    "print(\"Debates Dataset:\", DEBATES_DF_PATH)\n",
    "print(\"Embeddings:\", EMBEDDINGS_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Debates shape: (6316, 20), Embeddings shape: (6316, 384)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>speaker_normalized</th>\n",
       "      <th>speaker</th>\n",
       "      <th>party</th>\n",
       "      <th>winner</th>\n",
       "      <th>winner_party</th>\n",
       "      <th>year</th>\n",
       "      <th>debate_type</th>\n",
       "      <th>debate_id</th>\n",
       "      <th>utterance_id</th>\n",
       "      <th>lemmatized_text</th>\n",
       "      <th>token_count</th>\n",
       "      <th>decade</th>\n",
       "      <th>party_code</th>\n",
       "      <th>topic</th>\n",
       "      <th>probability</th>\n",
       "      <th>theme_name</th>\n",
       "      <th>subtheme_name</th>\n",
       "      <th>subtopic</th>\n",
       "      <th>subtopic_prob</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>good evening. the television and radio station...</td>\n",
       "      <td>Moderator</td>\n",
       "      <td>Moderator</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Kennedy</td>\n",
       "      <td>Democrat</td>\n",
       "      <td>1960</td>\n",
       "      <td>presidential</td>\n",
       "      <td>1960_1_Presidential_Nixon_Kennedy</td>\n",
       "      <td>1960_1_Presidential_Nixon_Kennedy_001</td>\n",
       "      <td>good evening the television and radio station ...</td>\n",
       "      <td>146</td>\n",
       "      <td>1960s</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6</td>\n",
       "      <td>0.289106</td>\n",
       "      <td>debate_format_procedure</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.332321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>mr. smith, mr. nixon. in the election of 1860,...</td>\n",
       "      <td>Candidate_D</td>\n",
       "      <td>Kennedy</td>\n",
       "      <td>Democrat</td>\n",
       "      <td>Kennedy</td>\n",
       "      <td>Democrat</td>\n",
       "      <td>1960</td>\n",
       "      <td>presidential</td>\n",
       "      <td>1960_1_Presidential_Nixon_Kennedy</td>\n",
       "      <td>1960_1_Presidential_Nixon_Kennedy_002</td>\n",
       "      <td>mr smith mr nixon in the election of 1860 abra...</td>\n",
       "      <td>1290</td>\n",
       "      <td>1960s</td>\n",
       "      <td>D</td>\n",
       "      <td>0</td>\n",
       "      <td>0.184597</td>\n",
       "      <td>foreign_policy_national_security</td>\n",
       "      <td>historical_foreign_policy_cuba_vietnam</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>mr. smith, senator kennedy. the things that se...</td>\n",
       "      <td>Candidate_R</td>\n",
       "      <td>Nixon</td>\n",
       "      <td>Republican</td>\n",
       "      <td>Kennedy</td>\n",
       "      <td>Democrat</td>\n",
       "      <td>1960</td>\n",
       "      <td>presidential</td>\n",
       "      <td>1960_1_Presidential_Nixon_Kennedy</td>\n",
       "      <td>1960_1_Presidential_Nixon_Kennedy_004</td>\n",
       "      <td>mr smith senator kennedy the thing that senato...</td>\n",
       "      <td>1406</td>\n",
       "      <td>1960s</td>\n",
       "      <td>R</td>\n",
       "      <td>0</td>\n",
       "      <td>0.154407</td>\n",
       "      <td>foreign_policy_national_security</td>\n",
       "      <td>historical_foreign_policy_cuba_vietnam</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text speaker_normalized  \\\n",
       "0  good evening. the television and radio station...          Moderator   \n",
       "1  mr. smith, mr. nixon. in the election of 1860,...        Candidate_D   \n",
       "2  mr. smith, senator kennedy. the things that se...        Candidate_R   \n",
       "\n",
       "     speaker       party   winner winner_party  year   debate_type  \\\n",
       "0  Moderator         NaN  Kennedy     Democrat  1960  presidential   \n",
       "1    Kennedy    Democrat  Kennedy     Democrat  1960  presidential   \n",
       "2      Nixon  Republican  Kennedy     Democrat  1960  presidential   \n",
       "\n",
       "                           debate_id                           utterance_id  \\\n",
       "0  1960_1_Presidential_Nixon_Kennedy  1960_1_Presidential_Nixon_Kennedy_001   \n",
       "1  1960_1_Presidential_Nixon_Kennedy  1960_1_Presidential_Nixon_Kennedy_002   \n",
       "2  1960_1_Presidential_Nixon_Kennedy  1960_1_Presidential_Nixon_Kennedy_004   \n",
       "\n",
       "                                     lemmatized_text  token_count decade  \\\n",
       "0  good evening the television and radio station ...          146  1960s   \n",
       "1  mr smith mr nixon in the election of 1860 abra...         1290  1960s   \n",
       "2  mr smith senator kennedy the thing that senato...         1406  1960s   \n",
       "\n",
       "  party_code  topic  probability                        theme_name  \\\n",
       "0        NaN      6     0.289106           debate_format_procedure   \n",
       "1          D      0     0.184597  foreign_policy_national_security   \n",
       "2          R      0     0.154407  foreign_policy_national_security   \n",
       "\n",
       "                            subtheme_name  subtopic  subtopic_prob  \n",
       "0                                     NaN      -1.0       0.332321  \n",
       "1  historical_foreign_policy_cuba_vietnam       5.0       1.000000  \n",
       "2  historical_foreign_policy_cuba_vietnam       5.0       1.000000  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# === LOAD DATA ===\n",
    "\n",
    "df = pd.read_csv(DEBATES_DF_PATH)\n",
    "embeddings = np.load(EMBEDDINGS_PATH)\n",
    "\n",
    "print(f\"Debates shape: {df.shape}, Embeddings shape: {embeddings.shape}\")\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Anchor Terms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Anchor terms defined with aliases:\n",
      "  freedom      → freedom, freedoms, liberty, liberties, free\n",
      "  security     → security, safety, protection, defense\n",
      "  america      → america, american, americans\n",
      "  taxes        → tax, taxes, taxation, taxpayer, taxpayers\n",
      "  immigration  → immigration, immigrant, immigrants, migrant, migrants, asylum, refugee, refugees, border, borders, border wall, border security, illegal alien, illegal aliens, deportation, deport, visa, visas\n",
      "  healthcare   → healthcare, health care, medicare, medicaid, obamacare, affordable care\n"
     ]
    }
   ],
   "source": [
    "# === ANCHOR TERMS WITH ALIASES ===\n",
    "\n",
    "# aliases are used to capture variations of the anchor terms\n",
    "# terms have been chosen based on common political themes in US debates that would be well represented in all decades\n",
    "ANCHORS = {\n",
    "    \"freedom\": [\"freedom\", \"freedoms\", \"liberty\", \"liberties\", \"free\"],\n",
    "    \"security\": [\"security\", \"safety\", \"protection\", \"defense\"],\n",
    "    \"america\": [\"america\", \"american\", \"americans\"],\n",
    "    \"taxes\": [\"tax\", \"taxes\", \"taxation\", \"taxpayer\", \"taxpayers\"],\n",
    "    \"immigration\": [\"immigration\", \"immigrant\", \"immigrants\", \"migrant\", \"migrants\", \n",
    "                \"asylum\", \"refugee\", \"refugees\", \"border\", \"borders\", \n",
    "                \"border wall\", \"border security\", \"illegal alien\", \"illegal aliens\", \n",
    "                \"deportation\", \"deport\", \"visa\", \"visas\"],\n",
    "    \"healthcare\": [\"healthcare\", \"health care\", \"medicare\", \"medicaid\", \"obamacare\", \"affordable care\"],\n",
    "}\n",
    "\n",
    "print(\"[INFO] Anchor terms defined with aliases:\")\n",
    "for k, v in ANCHORS.items():\n",
    "    print(f\"  {k:<12} → {', '.join(v)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Utterance: well, i've been a senator, donald...\n",
      "Matched anchors: []\n",
      "\n",
      "Utterance: no, let me go back and speak to the points that the president made, and let's get them correct. i did not say that the arizona law was a model for the nation in that aspect. i said that the e-verify portion of the arizona law, which is the portion of the law which says that employers could be able to determine whether someone is here illegally or not illegally, that that was a model for the nation. that's number one. number two, i asked the president a question, i think, hispanics and immigrants all over the nation have asked. he was asked this on univision the other day. why, when you said you'd file legislation in your first year, didn't you do it? and he didn't answer. he doesn't answer that question. he said the standard bearer wasn't for it. i'm glad you thought i was a standard bearer 4 years ago, but i wasn't. four years ago, you said in your first year, you would file legislation. in his first year, i was just getting—licking my wounds from having been beaten by john mccain, all right. i was not the standard bearer. my view is that this president should have honored his promise to do as he said. now, let me mention one other thing, and that is self-deportation says, let people make their own choice. what i was saying is we're not going to round up 12 million people, undocumented illegals, and take them out of the nation. instead, let people make their own choice. and if they find that they can't get the benefits here that they want and they can't find the job they want, then they'll make a decision to go a place where they have better opportunities. but i'm not in favor of rounding up people and taking them out of this country. i am in favor, as the president has said—and i agree with him—which is that if people have committed crimes, we've got to get them out of this country. let me mention something else the president said. it was a moment ago, and i didn't get a chance to—when he was describing chinese investments and so forth——\n",
      "Matched anchors: ['immigration']\n",
      "\n",
      "Utterance: all right. i think what happens is when you try to equate whether or not i have had military experience, that's the natural conclusion. it's about as valid as saying that you would have to be black in order to despise racism, that you'd have to be female in order to be terribly offended by sexism. and that's just not so. i think if you take a look at where i've been, both in the congress and where i intend to go, the type of person i am - i think that the people of this country can rely upon the fact that i will be a lender. i don't think the soviet union for one minute can sit down and make determination on what i will do if i'm ever in a position to have to do something with reference to the soviet union. quite frankly i'm prepared to do whatever is necessary in order to secure this country and make sure that security is maintained. secondly, if the soviet union were to ever believe that they could challenge the united states with any sort of nuclear forces or otherwise, if i were in a position of leadership in this country, they would be assured that they would be met with swift, concise and certain retaliation. let me just say one other thing now. the most important thing, though i think as a leader that what one has to do is get to the point where you're not put into that position. and the way you to that position of rnoving away from having to make a decision - armed force or anything else - is by moving toward arms control. and that's not what's been done over the past four years. i think that if you were to take a look at the failures of this administration that would have to be number one. i will not put myself in that position as a leader in this country. i will move immediately toward arms control negotiations.\n",
      "Matched anchors: ['security']\n",
      "\n",
      "Utterance: think about it this way.\n",
      "Matched anchors: []\n",
      "\n",
      "Utterance: and senator mccain during that period said that we should keep on deregulating because that's how the free enterprise system works. now, with respect to fannie mae, what senator mccain didn't mention is the fact that this bill that he talked about wasn't his own bill. he jumped on it a year after it had been introduced and it never got passed. and i never promoted fannie mae. in fact, senator mccain's campaign chairman's firm was a lobbyist on behalf of fannie mae, not me. so -- but, look, you're not interested in hearing politicians pointing fingers. what you're interested in is trying to figure out, how is this going to impact you? this is not the end of the process; this is the beginning of the process. and that's why it's going to be so important for us to work with homeowners to make sure that they can stay in their homes. the secretary already has the power to do that in the rescue package, but it hasn't been exercised yet. and the next president has to make sure that the next treasury secretary is thinking about how to strengthen you as a home buyer, you as a homeowner, and not simply think about bailing out banks on wall street.\n",
      "Matched anchors: ['freedom']\n"
     ]
    }
   ],
   "source": [
    "# === CHECK PRESENCE OF ANCHORS IN TEXT ===\n",
    "\n",
    "def match_anchor(text: str):\n",
    "    \"\"\"Return set of anchor keys present in a given text (alias-based).\"\"\"\n",
    "    text = str(text).lower()\n",
    "    found = set()\n",
    "    for anchor, aliases in ANCHORS.items():\n",
    "        for alias in aliases:\n",
    "            if alias in text:\n",
    "                found.add(anchor)\n",
    "    return list(found)\n",
    "\n",
    "# quick test on sample rows\n",
    "sample_texts = df[\"text\"].sample(5, random_state=RANDOM_SEED)\n",
    "for t in sample_texts:\n",
    "    print(f\"\\nUtterance: {t}\\nMatched anchors: {match_anchor(t)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[INFO] Utterances with at least one anchor term (candidates only): 2116 / 6316\n",
      "\n",
      "[INFO] Anchor frequencies (across candidate utterances):\n",
      "  freedom     : 290\n",
      "  america     : 1329\n",
      "  security    : 562\n",
      "  immigration : 166\n",
      "  taxes       : 718\n",
      "  healthcare  : 400\n"
     ]
    }
   ],
   "source": [
    "# === FILTER DEBATES TO ONLY UTTERANCES WITH ANCHORS (NO MODERATORS) ===\n",
    "\n",
    "df[\"matched_anchors\"] = df[\"text\"].apply(match_anchor)\n",
    "\n",
    "mask_has_anchor = df[\"matched_anchors\"].str.len() > 0\n",
    "mask_is_candidate = df[\"party\"].isin([\"Republican\", \"Democrat\", \"Independent\"])\n",
    "\n",
    "anchors_df = df[mask_has_anchor & mask_is_candidate].copy()\n",
    "\n",
    "print(f\"\\n[INFO] Utterances with at least one anchor term (candidates only): {len(anchors_df)} / {len(df)}\")\n",
    "\n",
    "# distribution of anchors across utterances\n",
    "from collections import Counter\n",
    "anchor_counter = Counter([a for anchors in anchors_df[\"matched_anchors\"] for a in anchors])\n",
    "print(\"\\n[INFO] Anchor frequencies (across candidate utterances):\")\n",
    "for k, v in anchor_counter.items():\n",
    "    print(f\"  {k:<12}: {v}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Compute Anchor Embeddings by Party and Decade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Anchored utterances embeddings shape: (2116, 384)\n"
     ]
    }
   ],
   "source": [
    "# === ALIGN EMBEDDINGS WITH FILTERED DATA ===\n",
    "\n",
    "# make sure indices align between df and embeddings\n",
    "assert len(df) == embeddings.shape[0], \"DataFrame and embeddings misaligned!\"\n",
    "\n",
    "# extract only candidate utterances with anchors\n",
    "anchor_idx = anchors_df.index.to_numpy()\n",
    "anchor_embeddings = embeddings[anchor_idx]\n",
    "\n",
    "print(f\"[INFO] Anchored utterances embeddings shape: {anchor_embeddings.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Expanded anchor rows: 3465\n"
     ]
    }
   ],
   "source": [
    "# === GROUP BY PARTY × DECADE × ANCHOR ===\n",
    "\n",
    "# decade column is already in df\n",
    "anchors_df[\"decade\"] = (anchors_df[\"year\"] // 10) * 10\n",
    "\n",
    "# expand rows for multiple matched anchors (e.g., 'freedom' and 'america' in one utterance)\n",
    "rows = []\n",
    "for i, row in anchors_df.iterrows():\n",
    "    emb = embeddings[i]\n",
    "    for anchor in row[\"matched_anchors\"]:\n",
    "        rows.append({\n",
    "            \"utterance_id\": row[\"utterance_id\"],\n",
    "            \"party\": row[\"party\"],\n",
    "            \"decade\": row[\"decade\"],\n",
    "            \"anchor\": anchor,\n",
    "            \"embedding\": emb\n",
    "        })\n",
    "\n",
    "anchor_long = pd.DataFrame(rows)\n",
    "\n",
    "print(f\"[INFO] Expanded anchor rows: {len(anchor_long)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Centroids table shape: (93, 5)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>anchor</th>\n",
       "      <th>party</th>\n",
       "      <th>decade</th>\n",
       "      <th>count</th>\n",
       "      <th>centroid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>america</td>\n",
       "      <td>Democrat</td>\n",
       "      <td>1960</td>\n",
       "      <td>16</td>\n",
       "      <td>[-0.018588753, -0.029245632, -0.0069335555, -0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>america</td>\n",
       "      <td>Democrat</td>\n",
       "      <td>1970</td>\n",
       "      <td>36</td>\n",
       "      <td>[-0.032048408, -0.045022864, 0.015777659, -0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>america</td>\n",
       "      <td>Democrat</td>\n",
       "      <td>1980</td>\n",
       "      <td>102</td>\n",
       "      <td>[-0.010267679, -0.011285566, 0.018477034, -0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>america</td>\n",
       "      <td>Democrat</td>\n",
       "      <td>1990</td>\n",
       "      <td>109</td>\n",
       "      <td>[-0.015049924, -0.015090035, 0.03112774, -0.03...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>america</td>\n",
       "      <td>Democrat</td>\n",
       "      <td>2000</td>\n",
       "      <td>191</td>\n",
       "      <td>[-0.018042397, -0.008161504, 0.032586254, -0.0...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    anchor     party  decade  count  \\\n",
       "0  america  Democrat    1960     16   \n",
       "1  america  Democrat    1970     36   \n",
       "2  america  Democrat    1980    102   \n",
       "3  america  Democrat    1990    109   \n",
       "4  america  Democrat    2000    191   \n",
       "\n",
       "                                            centroid  \n",
       "0  [-0.018588753, -0.029245632, -0.0069335555, -0...  \n",
       "1  [-0.032048408, -0.045022864, 0.015777659, -0.0...  \n",
       "2  [-0.010267679, -0.011285566, 0.018477034, -0.0...  \n",
       "3  [-0.015049924, -0.015090035, 0.03112774, -0.03...  \n",
       "4  [-0.018042397, -0.008161504, 0.032586254, -0.0...  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# === COMPUTE CENTROIDS PER GROUP ===\n",
    "\n",
    "from numpy.linalg import norm\n",
    "\n",
    "centroids = []\n",
    "for (anchor, party, decade), group in anchor_long.groupby([\"anchor\", \"party\", \"decade\"]):\n",
    "    group_embs = np.vstack(group[\"embedding\"].values)\n",
    "    centroid = group_embs.mean(axis=0)\n",
    "    centroids.append({\n",
    "        \"anchor\": anchor,\n",
    "        \"party\": party,\n",
    "        \"decade\": decade,\n",
    "        \"count\": len(group),\n",
    "        \"centroid\": centroid\n",
    "    })\n",
    "\n",
    "centroids_df = pd.DataFrame(centroids)\n",
    "\n",
    "print(f\"[INFO] Centroids table shape: {centroids_df.shape}\")\n",
    "centroids_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Analysis per Decade and Party"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1. Semantic Drift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Drift pairs computed: 75\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>anchor</th>\n",
       "      <th>decade1</th>\n",
       "      <th>decade2</th>\n",
       "      <th>drift</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(america, Democrat)</td>\n",
       "      <td>1960</td>\n",
       "      <td>1970</td>\n",
       "      <td>0.228105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(america, Democrat)</td>\n",
       "      <td>1970</td>\n",
       "      <td>1980</td>\n",
       "      <td>0.080583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(america, Democrat)</td>\n",
       "      <td>1980</td>\n",
       "      <td>1990</td>\n",
       "      <td>0.077667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(america, Democrat)</td>\n",
       "      <td>1990</td>\n",
       "      <td>2000</td>\n",
       "      <td>0.073599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(america, Democrat)</td>\n",
       "      <td>2000</td>\n",
       "      <td>2010</td>\n",
       "      <td>0.073523</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                anchor  decade1  decade2     drift\n",
       "0  (america, Democrat)     1960     1970  0.228105\n",
       "1  (america, Democrat)     1970     1980  0.080583\n",
       "2  (america, Democrat)     1980     1990  0.077667\n",
       "3  (america, Democrat)     1990     2000  0.073599\n",
       "4  (america, Democrat)     2000     2010  0.073523"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity, cosine_distances\n",
    "\n",
    "# === COSINE DISTANCE BETWEEN DECADES (semantic drift over time) ===\n",
    "\n",
    "drift_rows = []\n",
    "for anchor, group in centroids_df.groupby([\"anchor\", \"party\"]):\n",
    "    # sort by decade for consistency\n",
    "    group_sorted = group.sort_values(\"decade\")\n",
    "    decades = group_sorted[\"decade\"].tolist()\n",
    "    embeddings = np.vstack(group_sorted[\"centroid\"].values)\n",
    "    \n",
    "    # compute pairwise distances between consecutive decades\n",
    "    for i in range(1, len(decades)):\n",
    "        d1, d2 = decades[i-1], decades[i]\n",
    "        emb1, emb2 = embeddings[i-1], embeddings[i]\n",
    "        dist = cosine_distances([emb1], [emb2])[0][0]\n",
    "        drift_rows.append({\n",
    "            \"anchor\": anchor,\n",
    "            \"decade1\": d1,\n",
    "            \"decade2\": d2,\n",
    "            \"drift\": dist\n",
    "        })\n",
    "\n",
    "drift_df = pd.DataFrame(drift_rows)\n",
    "print(f\"[INFO] Drift pairs computed: {len(drift_df)}\")\n",
    "display(drift_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2. Party Divergence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Party divergence rows: 41\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>anchor</th>\n",
       "      <th>decade</th>\n",
       "      <th>divergence_RD</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>america</td>\n",
       "      <td>1960</td>\n",
       "      <td>0.184770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>america</td>\n",
       "      <td>1970</td>\n",
       "      <td>0.061974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>america</td>\n",
       "      <td>1980</td>\n",
       "      <td>0.050642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>america</td>\n",
       "      <td>1990</td>\n",
       "      <td>0.035553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>america</td>\n",
       "      <td>2000</td>\n",
       "      <td>0.026594</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    anchor  decade  divergence_RD\n",
       "0  america    1960       0.184770\n",
       "1  america    1970       0.061974\n",
       "2  america    1980       0.050642\n",
       "3  america    1990       0.035553\n",
       "4  america    2000       0.026594"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# === COSINE DISTANCE BETWEEN PARTIES (semantic divergence within a decade) ===\n",
    "\n",
    "divergence_rows = []\n",
    "for anchor, group in centroids_df.groupby([\"anchor\", \"decade\"]):\n",
    "    anchor_name, decade = anchor\n",
    "    parties = group[\"party\"].unique()\n",
    "    if \"Republican\" in parties and \"Democrat\" in parties:\n",
    "        emb_r = group[group[\"party\"]==\"Republican\"][\"centroid\"].values[0]\n",
    "        emb_d = group[group[\"party\"]==\"Democrat\"][\"centroid\"].values[0]\n",
    "        dist = cosine_distances([emb_r],[emb_d])[0][0]\n",
    "        divergence_rows.append({\n",
    "            \"anchor\": anchor_name,\n",
    "            \"decade\": decade,\n",
    "            \"divergence_RD\": dist\n",
    "        })\n",
    "\n",
    "divergence_df = pd.DataFrame(divergence_rows)\n",
    "print(f\"[INFO] Party divergence rows: {len(divergence_df)}\")\n",
    "display(divergence_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3. Exports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DONE] Saved drift results -> /Users/emmamora/Documents/GitHub/thesis/data/ideological_drift/semantic_drift.csv\n",
      "[DONE] Saved party divergence results -> /Users/emmamora/Documents/GitHub/thesis/data/ideological_drift/party_divergence.csv\n"
     ]
    }
   ],
   "source": [
    "# === SAVE OUTPUTS ===\n",
    "\n",
    "OUTPUT_PATH.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "drift_outfile = OUTPUT_PATH / \"semantic_drift.csv\"\n",
    "divergence_outfile = OUTPUT_PATH / \"party_divergence.csv\"\n",
    "\n",
    "drift_df.to_csv(drift_outfile, index=False)\n",
    "divergence_df.to_csv(divergence_outfile, index=False)\n",
    "\n",
    "print(f\"[DONE] Saved drift results -> {drift_outfile}\")\n",
    "print(f\"[DONE] Saved party divergence results -> {divergence_outfile}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Ancor-Theme Alignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Debate themes (2010s–2020s): (2980, 5)\n",
      "[INFO] Media chunks (2010s–2020s): (675, 20)\n"
     ]
    }
   ],
   "source": [
    "# === ADDITIONAL FILE PATHS ===\n",
    "\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "THEME_IDX_PATH = DATA_DIR / \"embeddings\" / \"debates_aligned_index.csv\"\n",
    "THEME_VEC_PATH = DATA_DIR / \"embeddings\" / \"debates_aligned_sbert.npy\"\n",
    "\n",
    "MEDIA_IDX_PATH = DATA_DIR / \"important\" / \"media_chunks_pred_balanced.csv\"\n",
    "MEDIA_VEC_PATH = DATA_DIR / \"embeddings\" / \"debates_media_theme_alignment_processed\" / \"media_chunks_pred_balanced_sbert.npy\"   \n",
    "\n",
    "# load theme centroids\n",
    "debate_theme_index = pd.read_csv(THEME_IDX_PATH)\n",
    "debate_theme_vecs = np.load(THEME_VEC_PATH)\n",
    "\n",
    "# load media chunks\n",
    "media_index = pd.read_csv(MEDIA_IDX_PATH)\n",
    "media_vecs = np.load(MEDIA_VEC_PATH)\n",
    "\n",
    "print(\"[INFO] Debate themes (2010s–2020s):\", debate_theme_index.shape)\n",
    "print(\"[INFO] Media chunks (2010s–2020s):\", media_index.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SUCCESS] CSV and embeddings are aligned\n"
     ]
    }
   ],
   "source": [
    "# === CHECK MEDIA INDEX-EMBEDDINGS ALIGNMENT ===\n",
    "\n",
    "if len(media_index) == media_vecs.shape[0]:\n",
    "    print(\"[SUCCESS] CSV and embeddings are aligned\")\n",
    "else:\n",
    "    print(\"[WARNING] Mismatch! CSV rows vs embeddings do not align\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Debate theme centroids: 2980\n"
     ]
    }
   ],
   "source": [
    "# === PREP DEBATE THEME CENTROIDS (aligned) ===\n",
    "\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "debate_theme_index = pd.read_csv(THEME_IDX_PATH)\n",
    "debate_theme_vecs = np.load(THEME_VEC_PATH)\n",
    "\n",
    "# mask for 2010s–2020s\n",
    "debate_theme_index[\"decade\"] = (debate_theme_index[\"year\"] // 10) * 10\n",
    "debate_themes = debate_theme_index.copy()\n",
    "debate_themes[\"embedding\"] = list(debate_theme_vecs)\n",
    "\n",
    "print(f\"[INFO] Debate theme centroids: {len(debate_themes)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Media theme centroids: 36\n"
     ]
    }
   ],
   "source": [
    "# === PREP MEDIA CHUNKS (balanced) ===\n",
    "\n",
    "media_index = pd.read_csv(MEDIA_IDX_PATH)\n",
    "media_vecs = np.load(MEDIA_VEC_PATH)\n",
    "\n",
    "media_index[\"embedding\"] = list(media_vecs)\n",
    "\n",
    "# aggregate into theme-level centroids\n",
    "media_themes = (\n",
    "    media_index.groupby([\"pred_theme\", \"year\"])\n",
    "    .apply(lambda g: np.mean(np.vstack(g[\"embedding\"].values), axis=0))\n",
    "    .reset_index()\n",
    "    .rename(columns={0: \"embedding\"})\n",
    ")\n",
    "media_themes[\"decade\"] = (media_themes[\"year\"] // 10) * 10\n",
    "\n",
    "print(f\"[INFO] Media theme centroids: {len(media_themes)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === FUNCTION TO COMPUTE TOP-N SIMILAR THEMES ===\n",
    "\n",
    "def top_similar(anchor_vec, theme_df, label_col=\"theme\", topn=3):\n",
    "    sims = cosine_similarity([anchor_vec], np.vstack(theme_df[\"embedding\"].values))[0]\n",
    "    theme_df = theme_df.copy()\n",
    "    theme_df[\"similarity\"] = sims\n",
    "    top_df = theme_df.sort_values(\"similarity\", ascending=False).head(topn)\n",
    "    return top_df[[label_col, \"similarity\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === MATCH ANCHORS TO THEMES ===\n",
    "\n",
    "alignment_rows = []\n",
    "\n",
    "for _, row in centroids_df.iterrows():\n",
    "    anchor = row[\"anchor\"]\n",
    "    party = row[\"party\"]\n",
    "    decade = row[\"decade\"]\n",
    "    anchor_vec = row[\"centroid\"]\n",
    "\n",
    "    # debates\n",
    "    debate_top = top_similar(anchor_vec, debate_themes, label_col=\"theme_name\", topn=3)\n",
    "    for _, drow in debate_top.iterrows():\n",
    "        alignment_rows.append({\n",
    "            \"anchor\": anchor,\n",
    "            \"party\": party,\n",
    "            \"decade\": decade,\n",
    "            \"domain\": \"debates\",\n",
    "            \"theme\": drow[\"theme_name\"],\n",
    "            \"similarity\": drow[\"similarity\"]\n",
    "        })\n",
    "\n",
    "    # media\n",
    "    media_top = top_similar(anchor_vec, media_themes, label_col=\"pred_theme\", topn=3)\n",
    "    for _, mrow in media_top.iterrows():\n",
    "        alignment_rows.append({\n",
    "            \"anchor\": anchor,\n",
    "            \"party\": party,\n",
    "            \"decade\": decade,\n",
    "            \"domain\": \"media\",\n",
    "            \"theme\": mrow[\"pred_theme\"],\n",
    "            \"similarity\": mrow[\"similarity\"]\n",
    "        })\n",
    "\n",
    "alignment_df = pd.DataFrame(alignment_rows)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DONE] Saved anchor–theme alignment results -> /Users/emmamora/Documents/GitHub/thesis/data/ideological_drift/anchor_theme_alignment.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>anchor</th>\n",
       "      <th>party</th>\n",
       "      <th>decade</th>\n",
       "      <th>domain</th>\n",
       "      <th>theme</th>\n",
       "      <th>similarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>america</td>\n",
       "      <td>Democrat</td>\n",
       "      <td>1960</td>\n",
       "      <td>debates</td>\n",
       "      <td>china_global_trade</td>\n",
       "      <td>0.585159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>america</td>\n",
       "      <td>Democrat</td>\n",
       "      <td>1960</td>\n",
       "      <td>debates</td>\n",
       "      <td>china_global_trade</td>\n",
       "      <td>0.574260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>america</td>\n",
       "      <td>Democrat</td>\n",
       "      <td>1960</td>\n",
       "      <td>debates</td>\n",
       "      <td>foreign_policy_national_security</td>\n",
       "      <td>0.568403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>america</td>\n",
       "      <td>Democrat</td>\n",
       "      <td>1960</td>\n",
       "      <td>media</td>\n",
       "      <td>foreign_policy_national_security</td>\n",
       "      <td>0.571128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>america</td>\n",
       "      <td>Democrat</td>\n",
       "      <td>1960</td>\n",
       "      <td>media</td>\n",
       "      <td>partisan_gridlock_new_leadership</td>\n",
       "      <td>0.570139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>america</td>\n",
       "      <td>Democrat</td>\n",
       "      <td>1960</td>\n",
       "      <td>media</td>\n",
       "      <td>foreign_policy_national_security</td>\n",
       "      <td>0.567073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>america</td>\n",
       "      <td>Democrat</td>\n",
       "      <td>1970</td>\n",
       "      <td>debates</td>\n",
       "      <td>government_spending_budget</td>\n",
       "      <td>0.703842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>america</td>\n",
       "      <td>Democrat</td>\n",
       "      <td>1970</td>\n",
       "      <td>debates</td>\n",
       "      <td>partisan_gridlock_new_leadership</td>\n",
       "      <td>0.669125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>america</td>\n",
       "      <td>Democrat</td>\n",
       "      <td>1970</td>\n",
       "      <td>debates</td>\n",
       "      <td>noise_or_unspecified</td>\n",
       "      <td>0.661748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>america</td>\n",
       "      <td>Democrat</td>\n",
       "      <td>1970</td>\n",
       "      <td>media</td>\n",
       "      <td>partisan_gridlock_new_leadership</td>\n",
       "      <td>0.716322</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    anchor     party  decade   domain                             theme  \\\n",
       "0  america  Democrat    1960  debates                china_global_trade   \n",
       "1  america  Democrat    1960  debates                china_global_trade   \n",
       "2  america  Democrat    1960  debates  foreign_policy_national_security   \n",
       "3  america  Democrat    1960    media  foreign_policy_national_security   \n",
       "4  america  Democrat    1960    media  partisan_gridlock_new_leadership   \n",
       "5  america  Democrat    1960    media  foreign_policy_national_security   \n",
       "6  america  Democrat    1970  debates        government_spending_budget   \n",
       "7  america  Democrat    1970  debates  partisan_gridlock_new_leadership   \n",
       "8  america  Democrat    1970  debates              noise_or_unspecified   \n",
       "9  america  Democrat    1970    media  partisan_gridlock_new_leadership   \n",
       "\n",
       "   similarity  \n",
       "0    0.585159  \n",
       "1    0.574260  \n",
       "2    0.568403  \n",
       "3    0.571128  \n",
       "4    0.570139  \n",
       "5    0.567073  \n",
       "6    0.703842  \n",
       "7    0.669125  \n",
       "8    0.661748  \n",
       "9    0.716322  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# === SAVE RESULTS ===\n",
    "\n",
    "alignment_outfile = OUTPUT_PATH / \"anchor_theme_alignment.csv\"\n",
    "alignment_df.to_csv(alignment_outfile, index=False)\n",
    "\n",
    "print(f\"[DONE] Saved anchor–theme alignment results -> {alignment_outfile}\")\n",
    "display(alignment_df.head(10))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "thesis-nlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
